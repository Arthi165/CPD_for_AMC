# -*- coding: utf-8 -*-
"""SP2n31ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y-RUHXTP0Qot8r1My6zoGhmp-r_qjojV
"""

# NN for signal proc. 2, n=31

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, Input, Conv1D, MaxPooling1D, Flatten, BatchNormalization, Reshape
from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler
import matplotlib.pyplot as plt

# Load CSV data
csv1_data = pd.read_csv('csv_H1_tanh10SNR10dB.csv').values.flatten()
csv2_data = pd.read_csv('csv_H2_tanh10SNR10dB.csv').values.flatten()

# Data generation function
def generate_data_cpd(N, csv1_data, csv2_data, T):
    Data = []
    Labels = []
    samples_per_tau = N // (T - 1)
    for tau in range(1, T):
        for _ in range(samples_per_tau):
            index_vec1 = np.random.choice(csv1_data, tau)
            index_vec2 = np.random.choice(csv2_data, T - tau)
            data_point = np.concatenate((index_vec1, index_vec2))
            Data.append(data_point)
            Labels.append(tau - 1)  # Ensure labels are zero-based

    X_vec = np.array(Data)
    y_vec = np.array(Labels)

    return X_vec, y_vec

# Learning Rate Scheduler function
def lr_schedule(epoch, lr):
    if epoch < 10:
        return lr + 0.0001
    elif epoch < 30:
        return lr
    else:
        return lr * 0.1

# Define a more complex hybrid model
def create_cnn_dnn_model(input_shape, num_classes):
    inputs = Input(shape=input_shape)

    # Reshape input to add the channel dimension
    x = Reshape((input_shape[0], 1))(inputs)

    # Convolutional layers
    x = Conv1D(64, kernel_size=3, activation='relu', padding='same')(x)
    x = MaxPooling1D(pool_size=2)(x)
    x = BatchNormalization()(x)

    x = Conv1D(128, kernel_size=3, activation='relu', padding='same')(x)
    x = MaxPooling1D(pool_size=2)(x)
    x = BatchNormalization()(x)

    x = Flatten()(x)

    # Dense layers
    x = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)
    x = Dropout(0.5)(x)
    x = Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)
    x = Dropout(0.5)(x)

    outputs = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs, outputs)
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    return model

# Define parameters
T = 7
N_test = 5000
num_runs = 3
N_train_values = [10000, 20000]

accuracies = []

for i, N_train in enumerate(N_train_values):
    run_accuracies = []

    for run in range(num_runs):
        # Generate training and test data
        X_train, y_train = generate_data_cpd(N_train, csv1_data, csv2_data, T)
        X_test, y_test = generate_data_cpd(N_test, csv1_data, csv2_data, T)

        input_shape = X_train.shape[1:]
        num_classes = T - 1  # Number of classes

        # Create and compile model
        model = create_cnn_dnn_model(input_shape, num_classes)

        # Callbacks
        reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=1e-6)
        lr_scheduler = LearningRateScheduler(lr_schedule)

        # Model training
        history = model.fit(X_train, y_train, epochs=50, batch_size=64,
                            callbacks=[reduce_lr, lr_scheduler], verbose=2, validation_data=(X_test, y_test))

        # Evaluate the model on test data
        y_pred = model.predict(X_test, verbose=0)
        predicted_labels = np.argmax(y_pred, axis=1)

        # Correctly compute accuracy
        accuracy = np.sum(predicted_labels == y_test) / N_test
        run_accuracies.append(accuracy)

    average_accuracy = np.mean(run_accuracies)
    accuracies.append(average_accuracy)
    print(f'N_train = {N_train}, Average Test accuracy over {num_runs} runs: {average_accuracy:.4f}')

# Plotting the accuracy graph
plt.figure(figsize=(10, 6))
plt.plot(N_train_values, accuracies, marker='o')
plt.title('Average Accuracy vs N_train')
plt.xlabel('N_train')
plt.ylabel('Average Accuracy')
plt.grid(True)
plt.show()